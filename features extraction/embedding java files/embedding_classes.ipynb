{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b2bba-0471-474b-b7d0-ab56cb5e62d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow\n",
    "!pip install torch\n",
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3871d44-b43b-4ef3-95af-583f321bd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 14:46:47.511383: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-14 14:46:47.584912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 14:46:49.891583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration,T5EncoderModel\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import pickle\n",
    "import gc\n",
    "from torch.nn import MaxPool2d\n",
    "import glob\n",
    "import re\n",
    "from transformers import logging\n",
    "from config import *\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65cc7e1-738a-4d92-b72e-efcd8f6b18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5EncoderModel.from_pretrained(MODEL_NAME)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176456d0-7d42-41ef-a6b8-be381234e418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1531175-47cf-47e7-b9d8-e4e24342127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = 'max_split_size_mb:512'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843aca2-ccad-4061-bd54-14f58bfd1270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize exception flag\n",
    "exception = False\n",
    "\n",
    "# Iterate through folders in the specified Java files path\n",
    "for folder in sorted(os.listdir(JAVA_FILES_PATH)):\n",
    "    folder_path = JAVA_FILES_PATH + \"/\" + folder\n",
    "    \n",
    "    # Skip certain file types\n",
    "    if '.csv' in folder or '.ipynb' in folder or '.txt' in folder:\n",
    "        continue\n",
    "    \n",
    "    print(folder)\n",
    "    \n",
    "    # Iterate through versions in the folder\n",
    "    for version in os.listdir(folder_path):\n",
    "        print(version)\n",
    "        version_path = folder_path + \"/\" + version\n",
    "        output_full_path = f'{version_path}/{OUTPUT_PATH}'\n",
    "        \n",
    "        # Skip if output path already exists\n",
    "        if os.path.isdir(output_full_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Create the output path directory if it doesn't exist\n",
    "            os.mkdir(output_full_path)\n",
    "        except OSError as error: \n",
    "            print(error)\n",
    "        \n",
    "        # Process each Java file in the version path\n",
    "        for filename in glob.iglob(f'{JAVA_FILES_PATH}/{folder}/{version}' + '/**/*.java', recursive=True):\n",
    "            if os.path.isdir(filename):\n",
    "                print(f\"{filename} is a directory\")\n",
    "                continue\n",
    "            \n",
    "            # Extract the file name\n",
    "            file = filename.split('/')[-1].split('.')[0]\n",
    "            \n",
    "            try:\n",
    "                # Attempt to create an embedding from the file\n",
    "                model = create_embedding_from_file(filename, model, version_path)\n",
    "            except RuntimeError:\n",
    "                # Handle runtime error (e.g., CUDA out of memory)\n",
    "                exception = True\n",
    "                del input_ids\n",
    "                torch.cuda.empty_cache() \n",
    "                gc.collect()\n",
    "                pass\n",
    "\n",
    "            if exception:\n",
    "                print(f'{version} {file} - the file cannot be encoded using the model')\n",
    "                model = T5EncoderModel.from_pretrained(MODEL_NAME)\n",
    "                model = model.to(device)\n",
    "                exception = False\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
